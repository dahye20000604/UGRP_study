{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassNetwork:\n",
    "    \n",
    "    def __init__(self, units=10,batch_size=32, learning_rate=0.1, l1=0,l2=0):\n",
    "        self.units=units\n",
    "        self.batch_size=batch_size\n",
    "        self.w1=None\n",
    "        self.b1=None\n",
    "        self.w2=None\n",
    "        self.b2=None\n",
    "        self.a1=None\n",
    "        self.losses=[]\n",
    "        self.val_losses=[]\n",
    "        self.lr=learning_rate\n",
    "        self.l1=l1\n",
    "        self.l2=l2\n",
    "        \n",
    "    def forpass(self,x):\n",
    "        z1=np.dot(x,self.w1)+self.b1\n",
    "        self.a1=self.sigmoid(z1)\n",
    "        z2=np.dot(self.a1,self.w2)+self.b2\n",
    "        return z2\n",
    "    \n",
    "    def backprop(self,x,err):\n",
    "        m=len(x)\n",
    "        w2_grad=np.dot(self.a1.T,err)/m\n",
    "        b2_grad=np.sum(err)/m\n",
    "        err_to_hidden=np.dot(err,self.w2.T)*self.a1*(1-self.a1)\n",
    "        w1_grad=np.dot(x.T,err_to_hidden)/m\n",
    "        b1_grad=np.sum(err_to_hidden,axis=0)/m\n",
    "        return w1_grad,b1_grad,w2_grad,b2_grad\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        a=1/(1+np.exp(-z))\n",
    "        return a\n",
    "    \n",
    "    def softmax(self,z):\n",
    "        exp_z=np.exp(z)\n",
    "        return exp_z/np.sum(exp_z,axis=1).reshape(-1,1)\n",
    "    \n",
    "    def init_weights(self, n_features, n_classes):\n",
    "        self.w1=np.random.normal(0,1,(n_features,self.units))\n",
    "        self.b1=np.zeros(self.units)\n",
    "        self.w2=np.random.normal(0,1,(self.units,n_classes))\n",
    "        self.b2=np.zeros(n_classes)\n",
    "        \n",
    "    def fit(self,x,y,epochs=100,x_val=None,y_val=None):\n",
    "        np.random.seed(42)\n",
    "        self.init_weights(x.shape[1],10)  #y.shape 대신에 10  \n",
    "        for i in range(epochs):\n",
    "            loss=0\n",
    "            #check=0                         #밑의 for문 때문에 추가\n",
    "            print('.',end='')\n",
    "            for x_batch,y_batch in self.gen_batch(x,y):\n",
    "                z=self.forpass(x_batch)\n",
    "                b=self.softmax(z)\n",
    "                b=np.clip(b,1e-10,1-1e-10)\n",
    "                check=0                         #밑의 for문 때문에 추가\n",
    "                a=self.training(x_batch,y_batch)\n",
    "                a=np.clip(a,1e-10,1-1e-10)\n",
    "                for i in y_batch:                 #loss구하는 것을 for 문으로 수정\n",
    "                    loss+=-np.log(b[check][i])          #b를 a로 바꾸면 왜 안될까..\n",
    "                    check+=1\n",
    "            self.losses.append((loss+self.reg_loss())/len(x))\n",
    "            self.update_val_loss(x_val,y_val)\n",
    "        \n",
    "    def gen_batch(self,x,y):\n",
    "        length=len(x)\n",
    "        bins=length//self.batch_size\n",
    "        if length % self.batch_size:\n",
    "            bins+=1          \n",
    "        indexes=np.random.permutation(np.arange(len(x)))\n",
    "        x=x[indexes]\n",
    "        y=y[indexes]\n",
    "        for i in range(bins):\n",
    "            start=self.batch_size*i\n",
    "            end=self.batch_size*(i+1)\n",
    "            yield x[start:end],y[start:end]\n",
    "            \n",
    "    def training(self,x,y):\n",
    "        m=len(x)\n",
    "        z=self.forpass(x)\n",
    "        a=self.softmax(z)\n",
    "        err=a\n",
    "        check=0\n",
    "        for i in a:\n",
    "            for j in range(len(i)):\n",
    "                if(y[check]==j):\n",
    "                    err[check][j]=-(1-i[j])\n",
    "                else:\n",
    "                    err[check][j]=i[j]\n",
    "            check+=1                                  #err 코드 수정\n",
    "        w1_grad,b1_grad,w2_grad,b2_grad=self.backprop(x,err)\n",
    "        w1_grad+=(self.l1*np.sign(self.w1)+self.l2*self.w1)/m\n",
    "        w2_grad+=(self.l1*np.sign(self.w2)+self.l2*self.w2)/m\n",
    "        self.w1-=self.lr*w1_grad\n",
    "        self.b1-=self.lr*b1_grad\n",
    "        self.w2-=self.lr*w2_grad\n",
    "        self.b2-=self.lr*b2_grad\n",
    "        return a\n",
    "    \n",
    "    def predict(self,x):\n",
    "        z=self.forpass(x)\n",
    "        return np.argmax(z,axis=1)\n",
    "    \n",
    "    def score(self,x,y):\n",
    "        return np.mean(self.predict(x)==y)             #np.argmax(y)수정\n",
    "    \n",
    "    def reg_loss(self):\n",
    "        return self.l1*(np.sum(np.abs(self.w1))+np.sum(np.abs(self.w2)))+self.l2/2*(np.sum(self.w1**2)+np.sum(self.w2**2))\n",
    "    \n",
    "    def update_val_loss(self,x_val,y_val):\n",
    "        z=self.forpass(x_val)\n",
    "        a=self.softmax(z)\n",
    "        a=np.clip(a,1e-10,1-1e-10)\n",
    "        val_loss=0\n",
    "        check=0\n",
    "        for i in y_val:                 #val_loss구하는 것을 for 문으로 수정\n",
    "            val_loss+=-np.log(a[check][i])\n",
    "            check+=1\n",
    "        self.val_losses.append((val_loss+self.reg_loss())/len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(48000, 784) (12000, 784)\n",
      "(48000,) (12000,)\n",
      "........................................"
     ]
    }
   ],
   "source": [
    "(x_train_all,y_train_all),(x_test,y_test)=tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(x_train_all.shape,y_train_all.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train_all,y_train_all,stratify=y_train_all,test_size=0.2,random_state=42)\n",
    "x_train=x_train/255\n",
    "x_val=x_val/255\n",
    "x_train=x_train.reshape(-1,784)\n",
    "x_val=x_val.reshape(-1,784)\n",
    "print(x_train.shape,x_val.shape)\n",
    "print(y_train.shape,y_val.shape)\n",
    "fc=MultiClassNetwork(units=100,batch_size=256)\n",
    "fc.fit(x_train,y_train,x_val=x_val,y_val=y_val,epochs=40)       #y_train_encoded대신에 y_train, y_val_encoded대신에 y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.025850929929987, 23.025850929929987, 23.025850929929987]\n",
      "[1.2963947840037717, 1.0146374139398724]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fc.losses)\n",
    "plt.plot(fc.val_losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.legend(['train_loss','val_loss'])\n",
    "print(fc.losses[0:3])\n",
    "print(fc.val_losses[:2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8150833333333334"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [2 1]\n",
      " [3 1]]\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,2],[2,3],[3,4]])\n",
    "for i in a:\n",
    "    i[1]=1\n",
    "print(a)\n",
    "b=np.array([1,3,2])\n",
    "for i in b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
